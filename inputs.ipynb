{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c33fd0b6-2642-450d-8d50-7effb7417bb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Instalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b4486c3-d013-407f-8ee4-c7229a8c25c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install openpyxl xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14c5d2f-8917-4684-9ead-f259466987d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Importación de las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be49b3a8-09b4-45af-b8a3-355ca78d4a03",
     "showTitle": false,
     "title": ""
    },
    "id": "5TRlcEM4pm9y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20fc573b-ff42-4735-bd4b-4ebda7d2e323",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46261e9e-d8bd-4556-b65c-d2deb4b5ee10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ruta = '/dbfs/FileStore/tables/'\n",
    "ruta_entradas = ruta + 'entradas/'\n",
    "ruta_entradas_modelo = ruta + 'entradas_modelo/'\n",
    "ruta_salidas = ruta + 'salidas/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a825db-1929-496c-9b1e-b1f57ea92941",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# borrar y crear carpetas vacias\n",
    "\n",
    "# cuando se agregue lo de SFTP tambien se agregará la ruta de entradas\n",
    "rutas = [ruta_entradas_modelo, ruta_salidas]\n",
    "\n",
    "for ruta_ in rutas:\n",
    "    if os.path.exists(ruta_):\n",
    "        print('\"' + ruta_ + '\" existe y hay que borrarla!')\n",
    "        shutil.rmtree(ruta_)\n",
    "    print('\"' + ruta_ + '\" se crea carpeta vacia')\n",
    "    os.mkdir(ruta_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1334d2b6-0e73-405e-98c9-5a38557531f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Carga de los archivos pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "588595f0-c9b7-4f46-a58e-5d52db7e4cbd",
     "showTitle": false,
     "title": ""
    },
    "id": "vC1As0gLOQw0"
   },
   "outputs": [],
   "source": [
    "df_espacios = pd.read_excel(ruta_entradas + '1_ESPACIOS_FISICOS.xlsx', 'MAESTRA V2_Final')\n",
    "df_profesionales = pd.read_excel(ruta_entradas + '2_PROFESIONALES.xlsx', 'MAESTRA')\n",
    "df_disp_espacios = pd.read_excel(ruta_entradas + '3_DISPONIBILIDAD_ESPACIOS_FISICOS.xlsx', 'MAESTRA')\n",
    "df_disp_profesionales = pd.read_excel(ruta_entradas + '4_DISPONIBILIDAD_DEL_PERSONAL.xlsx', 'MAESTRA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03776f4-2da9-4def-8638-7945115c2223",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Renombramiento y formateo de los atributos de las tablas\n",
    "\n",
    "Renombrar columnas en df_disp_profesionales:\n",
    "\n",
    "Se utiliza el método rename() de pandas para cambiar los nombres de las columnas en el DataFrame df_disp_profesionales. Los nombres de las columnas se modifican según un diccionario proporcionado. Por ejemplo, la columna 'Id Sede' se renombra como 'id_sede'.\n",
    "Convertir columnas a tipo de datos específico en df_disp_profesionales:\n",
    "\n",
    "Se utilizan los métodos astype() y str.upper().str.strip() para convertir las columnas 'id_persona', 'id_sede' y 'dia' del DataFrame df_disp_profesionales a tipos de datos específicos y para realizar operaciones de limpieza en los valores de las columnas.\n",
    "Filtrar columnas y combinar DataFrames en df_disp_profesionales:\n",
    "\n",
    "Se utiliza el método filter() con una expresión regular para seleccionar columnas que comiencen con 'h' seguidas de un número entre 0 y 23. Luego se utiliza fillna(0) para rellenar los valores faltantes en esas columnas con ceros. El DataFrame resultante se guarda en la variable tempi. Después, se utiliza pd.concat() para combinar las columnas seleccionadas con las columnas 'id_sede', 'id_persona' y 'dia' en df_disp_profesionales.\n",
    "Los pasos 1-3 se repiten para los DataFrames df_disp_espacios, df_profesionales y df_espacios con diferentes columnas y manipulaciones de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "225a8281-c4ea-4d0c-985f-928b539f69a0",
     "showTitle": false,
     "title": ""
    },
    "id": "1qnbYgBV834N"
   },
   "outputs": [],
   "source": [
    "df_disp_profesionales = df_disp_profesionales.rename(\n",
    "    columns = {\n",
    "        'Id Sede' : 'id_sede',\n",
    "        'Codigo Succes Factors' : 'id_persona',\n",
    "        'Día' : 'dia'\n",
    "    }\n",
    ")\n",
    "df_disp_profesionales['id_persona'] = df_disp_profesionales['id_persona'].astype(str)\n",
    "df_disp_profesionales['id_sede'] = df_disp_profesionales['id_sede'].astype(str)\n",
    "df_disp_profesionales['dia'] = df_disp_profesionales['dia'].str.upper().str.strip()\n",
    "\n",
    "tempi = df_disp_profesionales.filter(regex=r'^h([0-9]|(1[0-9])|(2[0-3]))$', axis=1).fillna(0) #.astype(bool)\n",
    "df_disp_profesionales = pd.concat([df_disp_profesionales[['id_sede', 'id_persona', 'dia']], tempi], axis=1)\n",
    "\n",
    "df_disp_espacios = df_disp_espacios.rename(\n",
    "    columns = {\n",
    "        'Id Sede' : 'id_sede',\n",
    "        'Id_Espacio_Físico' : 'id_espacio',\n",
    "        'Día' : 'dia'\n",
    "    }\n",
    ")\n",
    "df_disp_espacios['id_sede'] = df_disp_espacios['id_sede'].astype(str)\n",
    "df_disp_espacios['id_espacio'] = df_disp_espacios['id_espacio'].str.upper().str.strip()\n",
    "df_disp_espacios['dia'] = df_disp_espacios['dia'].str.upper().str.strip()\n",
    "\n",
    "tempi = df_disp_espacios.filter(regex=r'^h([0-9]|(1[0-9])|(2[0-3]))$', axis=1).fillna(0) #.astype(bool)\n",
    "df_disp_espacios = pd.concat([df_disp_espacios[['id_sede', 'id_espacio', 'dia']], tempi], axis=1)\n",
    "df_profesionales = df_profesionales.rename(\n",
    "    columns = {\n",
    "        'Id_Sede' : 'id_sede',\n",
    "        'Codigo Sf (Id Profesional)' : 'id_persona',\n",
    "        'Jornada Semanal Sede' : 'total_horas_semana',\n",
    "        'Horas Virtuales (No Consultorio) Semanal' : 'horas_virtual_semana',\n",
    "        'Tipo De Contrato' : 'tipo_contrato',\n",
    "        'Qualification Cargo (Id Qualification)' : 'cualificacion'\n",
    "    }\n",
    ")\n",
    "df_profesionales['id_sede'] = df_profesionales['id_sede'].astype(str)\n",
    "df_profesionales['id_persona'] = df_profesionales['id_persona'].astype(str)\n",
    "df_profesionales['cualificacion'] = df_profesionales['cualificacion'].str.upper().str.strip()\n",
    "df_profesionales['tipo_contrato'] = df_profesionales['tipo_contrato'].str.upper().str.strip()\n",
    "df_profesionales['horas_presencial_semana'] = (df_profesionales['total_horas_semana'] - df_profesionales['horas_virtual_semana']).round(0)\n",
    "\n",
    "df_profesionales = df_profesionales[['id_sede', 'id_persona', 'cualificacion', 'tipo_contrato', 'horas_presencial_semana']]\n",
    "\n",
    "# solo dejar profesionales con horas presenciales\n",
    "df_profesionales = df_profesionales[df_profesionales['horas_presencial_semana'] > 0]\n",
    "df_profesionales['horas_presencial_quincena'] = df_profesionales['horas_presencial_semana'].apply(lambda x: x * 2)\n",
    "\n",
    "\n",
    "df_espacios = df_espacios.rename(\n",
    "    columns = {\n",
    "        'Id_Sede' : 'id_sede',\n",
    "        'Id_espacio_físico' : 'id_espacio',\n",
    "        'Id_Qualification2' : 'cualificacion'\n",
    "    }\n",
    ")\n",
    "\n",
    "df_espacios['id_sede'] = df_espacios['id_sede'].astype(str)\n",
    "df_espacios['id_espacio'] = df_espacios['id_espacio'].str.upper().str.strip()\n",
    "df_espacios['cualificacion'] = df_espacios['cualificacion'].str.upper().str.strip()\n",
    "df_espacios = df_espacios[['id_sede', 'id_espacio', 'cualificacion']]\n",
    "df_espacios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95f0fc09-9475-464b-9b51-c2e0323e2451",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Formato de tildes, dejar los nombres de los días sin ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a3b701-7982-43e5-95db-7266caba5666",
     "showTitle": false,
     "title": ""
    },
    "id": "56rEJ3b2vorQ"
   },
   "outputs": [],
   "source": [
    "diccionario_tildes = {\n",
    "    'Á': 'A',\n",
    "    'É': 'E',\n",
    "    'Í': 'I',\n",
    "    'Ó': 'O',\n",
    "    'Ú': 'U'\n",
    "}\n",
    "df_disp_espacios['dia'] = df_disp_espacios['dia'].replace(diccionario_tildes, regex = True)\n",
    "df_disp_profesionales['dia'] = df_disp_profesionales['dia'].replace(diccionario_tildes, regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3d2101-ea2f-430f-abcc-b0b4f28d037c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Validacion de llaves\n",
    "\n",
    "Se crea una lista llamada errores_llaves para almacenar los errores en las claves.\n",
    "\n",
    "Se verifica la unicidad de la clave en el DataFrame df_espacios y se agrega un diccionario a errores_llaves si hay duplicados.\n",
    "\n",
    "Se repite el paso 2 para los DataFrames df_profesionales, df_disp_espacios y df_disp_profesionales, agregando diccionarios a errores_llaves si se encuentran duplicados en las claves correspondientes.\n",
    "\n",
    "Se utiliza un bloque try-except para imprimir un mensaje dependiendo de si se encontraron errores en las claves.\n",
    "\n",
    "Si se captura una excepción, se imprime la lista de errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2eeb987-8d1c-46e4-a231-02d667a47d26",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m89U5FG9pdSV",
    "outputId": "5242bea3-6021-49f1-b584-aedd7180e1d5"
   },
   "outputs": [],
   "source": [
    "errores_llaves = []\n",
    "\n",
    "# 1\n",
    "dif_esp = df_espacios['id_sede'].str.cat([df_espacios['id_espacio'], df_espacios['cualificacion']], sep='-').drop_duplicates().size\n",
    "if len(df_espacios) != dif_esp :\n",
    "  errores_llaves.append({'Maestro': 'Espacios', 'Total': len(df_espacios), 'Unicos': dif_esp})\n",
    "\n",
    "# 2\n",
    "dif_prof = df_profesionales['id_sede'].str.cat(df_profesionales['id_persona'], sep='-').drop_duplicates().size\n",
    "if len(df_profesionales) != dif_prof :\n",
    "  errores_llaves.append({'Maestro': 'Profesionales', 'Total': len(df_profesionales), 'Unicos': dif_prof})\n",
    "\n",
    "# 3\n",
    "dif_disp_esp = df_disp_espacios['id_sede'].str.cat([df_disp_espacios['id_espacio'], df_disp_espacios['dia']], sep='-').drop_duplicates().size\n",
    "if len(df_disp_espacios) != dif_disp_esp :\n",
    "  errores_llaves.append({'Maestro': 'Disp. espacios', 'Total': len(df_disp_espacios), 'Unicos': dif_disp_esp})\n",
    "\n",
    "# 4\n",
    "dif_disp_prof = df_disp_profesionales['id_sede'].str.cat([df_disp_profesionales['id_persona'], df_disp_profesionales['dia']], sep='-').drop_duplicates().size\n",
    "if len(df_disp_profesionales) != dif_disp_prof :\n",
    "  errores_llaves.append({'Maestro': 'Disp. profesionales', 'Total': len(df_disp_profesionales), 'Unicos': dif_disp_prof})\n",
    "\n",
    "\n",
    "try :\n",
    "  if len(errores_llaves) > 0 :\n",
    "    raise Exception\n",
    "  print('Llaves OK')\n",
    "except Exception :\n",
    "  print('Estos son los maestros en donde la llave no es unica: \\n', errores_llaves)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34470793-a657-4bc3-b6fb-d1a62b61a042",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Comienza la creación de las hojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57c8d2ac-447c-4285-be01-dc6eae1cb84e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "QiEgND0PYQPQ",
    "outputId": "e01bb53c-0826-42d7-a912-fee8f6464a72"
   },
   "outputs": [],
   "source": [
    "# [P_PQ(p,q)] Personas :: Persona, Qualificacion, (1)\n",
    "\n",
    "df_h_profesionales = df_profesionales[['id_sede', 'id_persona', 'cualificacion']]\n",
    "df_h_profesionales['valor'] = 1\n",
    "df_h_profesionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03b2014-6aa8-4926-938c-c138333184ee",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "IP_nldrKYPPJ",
    "outputId": "4962edfc-f361-49f2-e22f-eeaa15f4e3b4"
   },
   "outputs": [],
   "source": [
    "# [P_CQ(c,q)]  Espacios :: consultorio, Qualificacion, (1)\n",
    "\n",
    "df_h_espacios = df_espacios[['id_sede', 'id_espacio', 'cualificacion']]\n",
    "df_h_espacios['valor'] = 1\n",
    "\n",
    "#Que solo estén los de la anterior hoja\n",
    "\n",
    "# Obtener las cualificaciones únicas del primer DataFrame\n",
    "cualificaciones_unicas = df_h_profesionales['cualificacion'].unique()\n",
    "\n",
    "# Filtrar el segundo DataFrame para solo las filas donde la 'cualificacion' también esté en el primer DataFrame\n",
    "df_h_espacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ab58bc1-b31f-4039-bd4a-285365fd72dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cualificaciones_unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1490425a-9d3f-4939-8e5d-7c5961f71c0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    df_h_espacios = df_h_espacios[df_h_espacios['cualificacion'].isin(cualificaciones_unicas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f9b54c4-5771-4a70-b17e-0eeb7cd2a824",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_h_espacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "512d3bdc-c6d8-4b35-b9c6-93e3a4d57bf1",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y25_O7_b8SyL",
    "outputId": "393025fd-aec3-4b54-e3be-7511868eceee"
   },
   "outputs": [],
   "source": [
    "# [P_Di_PC(p,c)] personas x consultorios :: persona, espacio, (1)\n",
    "\n",
    "df_full_esp_prof = pd.merge(df_espacios, df_profesionales, how = 'outer', on = ['id_sede', 'cualificacion'])\n",
    "\n",
    "# profesionales_sin_consultorios\n",
    "profesionales_sin_consultorios = df_full_esp_prof[df_full_esp_prof['id_espacio'].isna()] # problemas!\n",
    "\n",
    "\n",
    "# consultorios_sin_profesionales\n",
    "esp_sin_prof_cualif = df_full_esp_prof[df_full_esp_prof['id_persona'].isna()]\n",
    "h_personas_espacios = df_full_esp_prof[~df_full_esp_prof['id_persona'].isna() & ~df_full_esp_prof['id_espacio'].isna()]\n",
    "h_personas_espacios['combinacion factible persona-consultorio (1:si)'] = 1\n",
    "\n",
    "\n",
    "consultorios_sin_profesionales = pd.merge(esp_sin_prof_cualif, h_personas_espacios, how = 'left', on = ['id_sede', 'id_espacio'])\n",
    "consultorios_sin_profesionales = consultorios_sin_profesionales[consultorios_sin_profesionales['id_persona_y'].isna()] # problemas tambien!\n",
    "\n",
    "\n",
    "hayErrores = False\n",
    "\n",
    "if profesionales_sin_consultorios.size > 0 :\n",
    "  profesionales_sin_consultorios.to_excel('profesionales_sin_consultorios.xlsx', index = False)\n",
    "  hayErrores = True\n",
    "\n",
    "if consultorios_sin_profesionales.size > 0 :\n",
    "  consultorios_sin_profesionales.to_excel('consultorios_sin_profesionales.xlsx', index = False)\n",
    "  hayErrores = True\n",
    "\n",
    "\n",
    "# pasar de ruta temporal a ruta de salida\n",
    "shutil.move('profesionales_sin_consultorios.xlsx', ruta_salidas)\n",
    "shutil.move('consultorios_sin_profesionales.xlsx', ruta_salidas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try :\n",
    "  if hayErrores :\n",
    "    raise Exception\n",
    "  print('Todos los profesionales pueden usar al menos un espacio fisico')\n",
    "  print('Todos los consultorios pueden ser usados por al menos un profesional')\n",
    "except Exception :\n",
    "  # si falloo por los profesionales:\n",
    "  print('En el maestro de profesionales hay personas con horas presenciales que no se pueden asignar porque la sede a la que pertenecen no tiene algun espacio fisico que tenga la cualificación. Por favor revisar el archivo \"profesionales_sin_consultorios.xlsx\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "792b881d-ec6e-48b9-ae48-7c849aa211dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Eliminando registros de aquellos profesionales que no tengan consultorios y consultorios que no tengan profesionales\n",
    "\n",
    "Esta parte del código se está utilizando para limpiar los dataframes y asegurarse de que solo contengan registros de profesionales que están asignados a consultorios y consultorios que tienen profesionales asignados. Esto es útil para asegurarse de que los datos son coherentes y están completos antes de realizar análisis adicionales o modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9564613b-867c-4fbe-b360-3f49dcec7331",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definiendo las listas de personas sin consultorio y consultorios sin persona\n",
    "unique_id_persona_sin_consultorio = profesionales_sin_consultorios['id_persona'].unique().tolist()\n",
    "unique_id_consultorio_sin_persona=consultorios_sin_profesionales['id_espacio'].unique().tolist()\n",
    "#Eliminando dichos registros de los dataframes relacionados con profesionales creados hasta ahora\n",
    "df_disp_profesionales.drop(df_disp_profesionales[df_disp_profesionales['id_persona'].isin(unique_id_persona_sin_consultorio)].index,inplace=True)\n",
    "df_profesionales.drop(df_profesionales[df_profesionales['id_persona'].isin(unique_id_persona_sin_consultorio)].index, inplace=True)\n",
    "df_h_profesionales.drop(df_h_profesionales[df_h_profesionales['id_persona'].isin(unique_id_persona_sin_consultorio)].index, inplace=True)\n",
    "#Mismo proceso pero para consultorios\n",
    "df_h_espacios.drop(df_h_espacios[df_h_espacios['id_espacio'].isin(unique_id_consultorio_sin_persona)].index, inplace=True)\n",
    "df_disp_espacios.drop(df_disp_espacios[df_disp_espacios['id_espacio'].isin(unique_id_consultorio_sin_persona)].index,inplace=True)\n",
    "df_espacios.drop(df_espacios[df_espacios['id_espacio'].isin(unique_id_consultorio_sin_persona)].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c38aab-5c1f-48ed-8e60-d16b4b09e9b6",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8Ytqd6VXRU81",
    "outputId": "9c5d7cad-d169-4061-b6e1-48513583a508"
   },
   "outputs": [],
   "source": [
    "# se transponen las tablas de disponibilidad\n",
    "df_disp_profesionales_transp = df_disp_profesionales.melt(id_vars=['id_sede', 'id_persona', 'dia'], var_name = 'hora', value_name = 'disponible')\n",
    "df_disp_espacios_transp = df_disp_espacios.melt(id_vars=['id_sede', 'id_espacio', 'dia'], var_name = 'hora', value_name = 'disponible')\n",
    "df_disp_espacios_transp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a84ae3-58ff-472c-9d89-53840b73380c",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "BMOigBV_Z0ku",
    "outputId": "1bc175e0-151a-4c9e-a475-b31091081bd8"
   },
   "outputs": [],
   "source": [
    "# quitar \"h\"s de las horas\n",
    "df_disp_profesionales_transp['hora'] = df_disp_profesionales_transp['hora'].str.extract(r'(\\d+)', expand = False).astype(int)\n",
    "df_disp_espacios_transp['hora'] = df_disp_espacios_transp['hora'].str.extract(r'(\\d+)', expand = False).astype(int)\n",
    "df_disp_espacios_transp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9717fd38-ce74-4ea7-ae8a-f39d1e855321",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bQMiRV98bqE",
    "outputId": "c5cd5386-d9e6-4363-f04d-488deca97366"
   },
   "outputs": [],
   "source": [
    "# [P_Di_PDH(p,d,h)] disp. personas :: persona, dia, hora, (1)\n",
    "h_disp_personas = df_disp_profesionales_transp[df_disp_profesionales_transp['disponible'] == True]\n",
    "h_disp_personas['esta la persona disponible (1:si)'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e686de6-e3d4-4c5e-a901-718b1a60ce2c",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHG1Ta248ffh",
    "outputId": "3e4e39cb-ef23-4f96-cece-01886a1ccf9f"
   },
   "outputs": [],
   "source": [
    "# [P_Di_CDH(c,d,h)] disp. espacios :: espacios, dia, hora, (0)\n",
    "h_disp_espacios = df_disp_espacios_transp[df_disp_espacios_transp['disponible'] == True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9242501-deb6-472c-85d9-e4b0151ac26f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IrNYNewsH3I",
    "outputId": "8a585fd3-26c7-4555-ea4c-5d8033c39457"
   },
   "outputs": [],
   "source": [
    "# cada profesional y espacio debe tener al menos una hora disponible\n",
    "\n",
    "# profesional\n",
    "columnas_suma_prof = df_disp_profesionales.columns[3:27]\n",
    "df_disp_profesionales[columnas_suma_prof] = df_disp_profesionales[columnas_suma_prof].replace(' ', 0).astype(float)\n",
    "df_disp_profesionales['suma'] = df_disp_profesionales[columnas_suma_prof].sum(axis = 1)\n",
    "\n",
    "df_prof_sin_disp = pd.merge(df_profesionales, df_disp_profesionales[df_disp_profesionales['suma'] > 0], how = 'left', on = ['id_sede', 'id_persona'])\n",
    "df_prof_sin_disp = df_prof_sin_disp[df_prof_sin_disp['suma'].isna()]\n",
    "#print(df_esp_sin_disp)\n",
    "\n",
    "\n",
    "# espacio\n",
    "columnas_suma_esp = df_disp_espacios.columns[3:27]\n",
    "df_disp_espacios[columnas_suma_esp] = df_disp_espacios[columnas_suma_esp].replace(' ', 0).astype(float)\n",
    "df_disp_espacios['suma'] = df_disp_espacios[columnas_suma_esp].sum(axis = 1)\n",
    "\n",
    "df_esp_sin_disp = pd.merge(df_espacios, df_disp_espacios[df_disp_espacios['suma'] > 0], how = 'left', on = ['id_sede', 'id_espacio'])\n",
    "df_esp_sin_disp = df_esp_sin_disp[df_esp_sin_disp['suma'].isna()]\n",
    "#print(df_esp_sin_disp)\n",
    "\n",
    "\n",
    "\n",
    "# y si comparamos cuantas horas tienen los profesionales vs las que deben ser asignadas?\n",
    "# Deben tener como minimo disponible el mismo numero de horas que deben trabajar\n",
    "\n",
    "\n",
    "try :\n",
    "  if len(df_prof_sin_disp) > 0 | len(df_esp_sin_disp) > 0 :\n",
    "    raise Exception\n",
    "  print('Todos los profesionales cuentan con al menos una hora de disponibilidad')\n",
    "  print('Todos los consultorios cuentan con al menos una hora de disponibilidad')\n",
    "  \n",
    "except Exception :\n",
    "  print('Hay problemas, ya sea con profesionales que no pueden ser asignados o a espacios fisicos que no pueden ser asignados. Revisar archivo(s) de salida.')\n",
    "  \n",
    "  df_prof_sin_disp.to_excel('Profesionales_sin_disponibilidad.xlsx', index = False)\n",
    "  shutil.move('Profesionales_sin_disponibilidad.xlsx', ruta_salidas)\n",
    "\n",
    "  df_esp_sin_disp.to_excel('Espacios_sin_disponibilidad.xlsx', index = False)\n",
    "  shutil.move('Espacios_sin_disponibilidad.xlsx', ruta_salidas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb0c641-7948-44f7-b463-05073a6b0bd6",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "Qn0YwDaC0Ff0",
    "outputId": "0d6dc4ac-9058-4ed7-e66c-db405699bfaa"
   },
   "outputs": [],
   "source": [
    "# [P_Hmax_PD(p,d)] horas maximas\n",
    "\n",
    "df_h_horas_max = pd.DataFrame({ 'Persona' : [], 'Horas presenciales contratadas semana' : [] })\n",
    "df_h_horas_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3ebab9-72b0-4775-9c1e-4db0c145c4a0",
     "showTitle": false,
     "title": ""
    },
    "id": "mTJOoMWHYZcN"
   },
   "outputs": [],
   "source": [
    "# [P_Hmin_PD(p,d)] horas minimas :: persona, dia, horas_min\n",
    "\n",
    "h_horas_min_t = df_profesionales[~df_profesionales['tipo_contrato'].str.contains('PRESTA')][['id_sede', 'id_persona']]\n",
    "h_horas_min_t['horas_min'] = 4\n",
    "\n",
    "opciones_dia = df_disp_profesionales['dia'].unique().tolist()\n",
    "\n",
    "h_horas_min = pd.DataFrame()\n",
    "\n",
    "for dia in opciones_dia:\n",
    "  tempi = h_horas_min_t\n",
    "  tempi['dia'] = dia\n",
    "  h_horas_min = pd.concat([h_horas_min, tempi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcad18f1-d9a9-4ffb-9057-82b82e4f89fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Quitando los festivos para P_HMIN_PD\n",
    "\n",
    "h_horas_min = h_horas_min[h_horas_min['dia'] != 'FESTIVO']\n",
    "print(h_horas_min.shape)\n",
    "h_horas_min = h_horas_min[h_horas_min['dia'] != 'FESTIVO 2']\n",
    "print(h_horas_min.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a00e690-51d4-4e02-bea1-71ec281f5f1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "h_horas_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d097258-f09c-4fd0-abbb-b32516157f30",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GMP4Dqwb_ey4",
    "outputId": "2bd42512-8ea1-49b4-9136-499df49de294"
   },
   "outputs": [],
   "source": [
    "# [P_Di_TH(t,h)] tipos de turnos :: \"T\"tiempo_horaini, horaini, (1)\n",
    "\n",
    "max_horas = 12\n",
    "\n",
    "tempi = df_disp_espacios_transp[df_disp_espacios_transp['disponible'] == True]\n",
    "tempi = tempi.groupby('id_sede')['hora'].agg(['min', 'max'])\n",
    "\n",
    "l_sedes = []\n",
    "l_turnos = []\n",
    "l_horas = []\n",
    "\n",
    "for index, row in tempi.iterrows():\n",
    "    for i in range(1, max_horas + 1):\n",
    "        for j in range(row['min'], row['max'] + 2 - i):\n",
    "            for k in range(j, j + i):\n",
    "                l_sedes.append(index)\n",
    "                l_turnos.append(f\"T{i}_{j}\")\n",
    "                l_horas.append(k)\n",
    "\n",
    "h_turnos = pd.DataFrame({'id_sede': l_sedes, 'turno': l_turnos, 'hora': l_horas})\n",
    "h_turnos['el turno esta activo (1:si)'] = 1\n",
    "h_turnos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5031eb2-d7e6-4da0-a74f-d92a05c1859d",
     "showTitle": false,
     "title": ""
    },
    "id": "cbWE1nY_tzcT"
   },
   "outputs": [],
   "source": [
    "# [P_Hcon_P(p)] horas presenciales :: persona, horas quincena\n",
    "\n",
    "h_horas = df_profesionales[['id_sede', 'id_persona', 'horas_presencial_quincena']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0197c8aa-746c-4cd1-9c4b-a33084d15067",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8YyqsodcinoG",
    "outputId": "7e2de188-3f4e-45b7-dff3-ee260e8d7a8a"
   },
   "outputs": [],
   "source": [
    "# [P_Tmax_PD(p,d)] combinaciones turnos-consultorios maximo permitido :: persona, dia, num combinaciones turnos-consultorios maximo permitido\n",
    "\n",
    "# Función para contar los conjuntos de unos en una fila\n",
    "def contar_conjuntos_unos(row):\n",
    "    contador = 0\n",
    "    conjuntos = 0\n",
    "\n",
    "    for valor in row[3:]:\n",
    "        if valor == 1:\n",
    "            contador += 1\n",
    "        else:\n",
    "            if contador > 0:\n",
    "                conjuntos += 1\n",
    "            contador = 0\n",
    "\n",
    "    if contador > 0:\n",
    "        conjuntos += 1\n",
    "\n",
    "    return conjuntos\n",
    "\n",
    "# Crear nueva columna con la cantidad de conjuntos de unos por registro\n",
    "df_disp_profesionales['max_turnos'] = df_disp_profesionales.apply(contar_conjuntos_unos, axis = 1)\n",
    "\n",
    "\n",
    "h_combinaciones_turnos = df_disp_profesionales[['id_sede', 'id_persona', 'dia', 'max_turnos']]\n",
    "\n",
    "h_combinaciones_turnos = h_combinaciones_turnos[h_combinaciones_turnos['dia'] != 'FESTIVO']\n",
    "h_combinaciones_turnos = h_combinaciones_turnos[h_combinaciones_turnos['dia'] != 'FESTIVO 2']\n",
    "h_combinaciones_turnos\n",
    "\n",
    "\n",
    "# inicialmente las personas que tiene las disponibilidad continua, van a tener un unico turno (eso es lo que está plastamado en la tabla)\n",
    "# es posible que al momento de ejecutar el modelo de optimización queden muchas horas sin asignar, se puede ejecutar una segunda vez, reemplazando los 1s por 0s\n",
    "# si es mucho mas optimo, se modificaria este trozo del codigo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a38fd12d-a47e-4008-b0a0-6bf3fbd99a3f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "RocLqj3G0K6O",
    "outputId": "0c1b657f-dd39-4951-e736-ff9cc90422eb"
   },
   "outputs": [],
   "source": [
    "# [3*] Dias semana\n",
    "\n",
    "dias_semana = {\n",
    "    'semana' : [\n",
    "        'semana_1', 'semana_1', 'semana_1', 'semana_1', 'semana_1', 'semana_1', 'semana_1',\n",
    "        'semana_2', 'semana_2', 'semana_2', 'semana_2', 'semana_2', 'semana_2', 'semana_2',\n",
    "    ],\n",
    "    'dia' : [\n",
    "        'LUNES', 'MARTES', 'MIERCOLES', 'JUEVES', 'VIERNES', 'SABADO', 'DOMINGO',\n",
    "        'LUNES 2', 'MARTES 2', 'MIERCOLES 2', 'JUEVES 2', 'VIERNES 2','SABADO 2', 'DOMINGO 2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_h_dias_semana = pd.DataFrame(dias_semana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58e19b94-a9d1-46ed-82cc-820b12fcafc8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creacion de los archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "804052bd-a842-4c15-988e-0a23f1862eb0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Preparando los archivos, renombrando columnas y demás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d236819-23c8-40c5-bfd1-370e3b62e9ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preparando las hojas para el export:\n",
    "sedes=df_profesionales['id_sede'].unique()\n",
    "#P_PQ(p,q)\n",
    "#df_h_profesionales_test=df_h_profesionales\n",
    "df_h_profesionales.rename(columns={'id_persona': 'Persona', 'cualificacion': 'Qualificacion'}, inplace=True)\n",
    "df_h_profesionales = df_h_profesionales[['Persona', 'Qualificacion', 'valor','id_sede']]\n",
    "df_h_profesionales\n",
    "\n",
    "#P_CQ\n",
    "df_h_espacios.rename(columns={'id_espacio':'consultorio','cualificacion':'Qualificacion'},inplace=True)\n",
    "df_h_espacios=df_h_espacios[['consultorio','Qualificacion','valor','id_sede']]\n",
    "df_h_espacios\n",
    "\n",
    "#P_Di_PC\n",
    "\n",
    "h_personas_espacios.rename(columns={'id_persona':'persona','id_espacio':'consultorio'},inplace=True)\n",
    "h_personas_espacios=h_personas_espacios[['persona','consultorio','combinacion factible persona-consultorio (1:si)','id_sede']]\n",
    "h_personas_espacios\n",
    "\n",
    "#P_Di_PDH\n",
    "h_disp_personas.rename(columns={'id_persona':'persona'},inplace=True)\n",
    "h_disp_personas=h_disp_personas[['persona','dia','hora','esta la persona disponible (1:si)','id_sede']]\n",
    "h_disp_personas\n",
    "\n",
    "#P_Di_PCH\n",
    "\n",
    "h_disp_espacios.rename(columns={'id_espacio':'consultorio','disponible':'esta disponible el consultorio (0:no)'},inplace=True)\n",
    "\n",
    "\n",
    "#P_Hmax_PD -> df_h_horas_max --> hoja en blanco\n",
    "\n",
    "#P_Hmin_PD\n",
    "\n",
    "h_horas_min.rename(columns={'id_persona':'persona', 'horas_min':'horas minimas de trabajo'},inplace=True)\n",
    "h_horas_min=h_horas_min[['persona','dia','horas minimas de trabajo','id_sede']]\n",
    "\n",
    "\n",
    "#P_Di_TH\n",
    "\n",
    "h_turnos=h_turnos[['turno','hora','el turno esta activo (1:si)','id_sede']]\n",
    "\n",
    "#P_Hcon_P\n",
    "\n",
    "h_horas.rename(columns={'id_persona':'Persona', 'horas_presencial_quincena':'Horas presenciales contratadas periodo'},inplace=True)\n",
    "h_horas=h_horas[['Persona','Horas presenciales contratadas periodo','id_sede']]\n",
    "\n",
    "#P_Tmax_PD\n",
    "h_combinaciones_turnos.rename(columns={'id_persona':'persona','max_turnos':'combinaciones turnos-consultorios maximo permitido'},inplace=True)\n",
    "\n",
    "#uno DFs en blanco --------------- PENDING\n",
    "\n",
    "h_sim_PDD=pd.DataFrame()\n",
    "h_sim_PCDD=pd.DataFrame()\n",
    "h_p_fat=pd.DataFrame()\n",
    "\n",
    "#dias semana\n",
    "df_dias_semana = pd.DataFrame(dias_semana)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09be9443-2a42-4847-9c47-6a6976331de9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#P_FAT10_PDHDH\n",
    "\n",
    "# Mapeamos los días de la semana a números\n",
    "dia_a_numero = {\n",
    "    'LUNES': 1,\n",
    "    'MARTES': 2,\n",
    "    'MIERCOLES': 3,\n",
    "    'JUEVES': 4,\n",
    "    'VIERNES': 5,\n",
    "    'SABADO': 6,\n",
    "    'DOMINGO': 7,\n",
    "    'LUNES 2': 8,\n",
    "    'MARTES 2': 9,\n",
    "    'MIERCOLES 2': 10,\n",
    "    'JUEVES 2': 11,\n",
    "    'VIERNES 2': 12,\n",
    "    'SABADO 2': 13,\n",
    "    'DOMINGO 2': 14\n",
    "}\n",
    "\n",
    "# Aplicamos la transformación al dataframe\n",
    "h_disp_personas['dia_num'] = h_disp_personas['dia'].map(dia_a_numero)\n",
    "\n",
    "# Creamos una copia ordenada del dataframe\n",
    "h_disp_personas_ordenado = h_disp_personas.sort_values(['persona', 'dia_num', 'hora'])\n",
    "\n",
    "# Creamos un nuevo dataframe con la información desplazada, solo para 'dia', 'hora', y 'dia_num'\n",
    "h_disp_personas_ordenado[['dia2', 'hora2', 'dia_num2']] = h_disp_personas_ordenado.groupby('persona')[['dia', 'hora', 'dia_num']].shift(-1)\n",
    "\n",
    "# Ahora, tenemos que tener en cuenta que cuando cambiamos de día, la hora se reinicia a 0.\n",
    "# Por lo tanto, cuando calculamos la diferencia de horas, si es negativa, significa que hemos cambiado de día y debemos agregar 24 a la hora del segundo día.\n",
    "h_disp_personas_ordenado['diff_hora'] = (h_disp_personas_ordenado['hora2'] + 24) - h_disp_personas_ordenado['hora']\n",
    "\n",
    "# Creamos una máscara para filtrar solo aquellos registros donde la diferencia de tiempo es menor a 10 horas y el día es consecutivo.\n",
    "mask = ((h_disp_personas_ordenado['diff_hora'] <= 10) & (h_disp_personas_ordenado['dia_num2'] - h_disp_personas_ordenado['dia_num'] == 1))\n",
    "\n",
    "# Filtramos el dataframe original con la máscara para obtener las filas conflictivas\n",
    "conflictos = h_disp_personas_ordenado.loc[mask]\n",
    "\n",
    "# Seleccionamos solo las columnas que nos interesan, incluyendo 'id_sede'\n",
    "conflictos = conflictos[['persona', 'dia', 'hora', 'id_sede', 'dia2', 'hora2']]\n",
    "\n",
    "# Eliminamos las filas donde dia2 o hora2 son NaN (esto sucederá en la última fila de cada grupo)\n",
    "conflictos = conflictos.dropna(subset=['dia2', 'hora2'])\n",
    "\n",
    "# Convertimos hora2 a int ya que después de shift se convierte en float\n",
    "conflictos['hora2'] = conflictos['hora2'].astype(int)\n",
    "\n",
    "h_p_fat=conflictos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "624a24ab-b6f5-4407-b641-6359202eee75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Antes de crear los archivos nuevos para el modelo se deben borrar \n",
    "# # los que puedan existir de ejecuciones anteriores\n",
    "\n",
    "# # Ordenar: si existen las carpetas o si no existen, si tiene archivos, o si podemos borrar esto al utilizar SFTP **********************\n",
    "\n",
    "# # Borra la carpeta y su contenido\n",
    "# shutil.rmtree(ruta_entradas_modelo)\n",
    "\n",
    "# # Crea la carpeta vacia\n",
    "# os.mkdir(ruta_entradas_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d4112a0-52b2-484c-a7b3-7f6eafa279f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Escitura de los archivos:\n",
    "'''\n",
    "for sede in sedes:\n",
    "    ruta='C:\\\\Users\\\\juanp\\\\Desktop\\\\Work\\\\Synaptica\\\\SURA\\\\Inputs\\\\Results\\\\'\n",
    "    nombre_archivo=f'archivo_excel_{sede}.xlsx'\n",
    "    writer=pd.ExcelWriter(ruta+nombre_archivo,engine='xlsxwriter')\n",
    "    df_h_profesionales[df_h_profesionales['id_sede']==sede].to_excel(writer,sheet_name='P_PQ(p,q)')\n",
    "    df_h_espacios[df_h_espacios['id_sede']==sede].to_excel(writer,sheet_name='P_CQ(c,q)')\n",
    "    h_personas_espacios[h_personas_espacios['id_sede']==sede].to_excel(writer,sheet_name='P_Di_PC(p,c)')\n",
    "    h_disp_personas[h_disp_personas['id_sede']==sede].to_excel(writer,sheet_name='P_Di_PDH(p,d,h)')\n",
    "    h_disp_espacios[h_disp_espacios['id_sede']==sede].to_excel(writer,sheet_name='P_Di_CDH(c,d,h)')\n",
    "    df_h_horas_max.to_excel(writer,sheet_name='P_Hmax_PD(p,d)')\n",
    "    h_horas_min[h_horas_min['id_sede']==sede].to_excel(writer,sheet_name='P_Hmin_PD')\n",
    "    h_turnos[h_turnos['id_sede']==sede].to_excel(writer,sheet_name='P_Di_TH(t,h)')\n",
    "    h_horas[h_horas['id_sede']==sede].to_excel(writer,sheet_name='P_Hcon_P(p)')\n",
    "    h_combinaciones_turnos[h_combinaciones_turnos['id_sede']==sede].to_excel(writer,sheet_name='P_Tmax_PD(p,d)')\n",
    "    h_sim_PDD.to_excel(writer,sheet_name='P_SIM_PDD_(p,d,d)')\n",
    "    h_sim_PCDD.to_excel(writer,sheet_name='P_SIM_PCDD_(p,c,d,d)')\n",
    "    h_p_fat[h_p_fat['id_sede']==sede].to_excel(writer,sheet_name='P_Fat10_PDHDH_(p,d,h,d,h)')\n",
    "    df_dias_semana.to_excel(writer,sheet_name='Dias_semana')\n",
    "    writer.save()\n",
    "'''\n",
    "for sede in sedes:\n",
    "\n",
    "    now_= datetime.datetime.now()\n",
    "    timestamp_ = datetime.datetime.timestamp(now_)\n",
    "    ruta_tmp = f'temp_{timestamp_}.xlsx' # esta ruta se utiliza mientras se termina de modificar el archivo\n",
    "    writer = ExcelWriter(ruta_tmp)\n",
    "    ruta_real = ruta_entradas_modelo + f'archivo_excel_{sede}.xlsx' # esta es la ruta final\n",
    "\n",
    "    # Hoja P_PQ(p,q)\n",
    "    df_h_profesionales[df_h_profesionales['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_PQ(p,q)', index=False)\n",
    "\n",
    "    # Hoja P_CQ(c,q)\n",
    "    df_h_espacios[df_h_espacios['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_CQ(c,q)', index=False)\n",
    "\n",
    "    # Hoja P_Di_PC(p,c)\n",
    "    h_personas_espacios[h_personas_espacios['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_Di_PC(p,c)', index=False)\n",
    "\n",
    "    # Hoja P_Di_PDH(p,d,h)\n",
    "    h_disp_personas[h_disp_personas['id_sede'] == sede].drop(['id_sede','dia_num'], axis=1).to_excel(writer, sheet_name='P_Di_PDH(p,d,h)', index=False)\n",
    "\n",
    "    # Hoja P_Di_CDH(c,d,h)\n",
    "    h_disp_espacios[h_disp_espacios['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_Di_CDH(c,d,h)', index=False)\n",
    "\n",
    "    # Hoja P_Hmax_PD(p,d)\n",
    "    df_h_horas_max.to_excel(writer, sheet_name='P_Hmax_PD(p,d)', index=False)\n",
    "\n",
    "    # Hoja P_Hmin_PD\n",
    "    h_horas_min[h_horas_min['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_Hmin_PD(p,d)', index=False)\n",
    "\n",
    "    # Hoja P_Di_TH(t,h)\n",
    "    h_turnos[h_turnos['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_Di_TH(t,h)', index=False)\n",
    "\n",
    "    # Hoja P_Hcon_P(p)\n",
    "    h_horas[h_horas['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_Hcon_P(p)', index=False)\n",
    "\n",
    "    # Hoja P_Tmax_PD(p,d)\n",
    "    h_combinaciones_turnos[h_combinaciones_turnos['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_Tmax_PD(p,d)', index=False)\n",
    "\n",
    "    # Hoja P_SIM_PDD_(p,d,d)\n",
    "    h_sim_PDD.to_excel(writer, sheet_name='P_Sim_PDD_(p,d,d)', index=False)\n",
    "\n",
    "    # Hoja P_SIM_PCDD_(p,c,d,d)\n",
    "    h_sim_PCDD.to_excel(writer, sheet_name='P_Sim_PCDD_(p,c,d,d)', index=False)\n",
    "\n",
    "    # Hoja P_Fat10_PDHDH_(p,d,h,d,h)\n",
    "    h_p_fat[h_p_fat['id_sede'] == sede].drop('id_sede', axis=1).to_excel(writer, sheet_name='P_Fat10_PDHDH_(p,d,h,d,h)', index=False)\n",
    "\n",
    "    # Hoja Dias_semana\n",
    "    df_dias_semana.to_excel(writer, sheet_name='Dias_semana', index=False)\n",
    "\n",
    "    writer.save()\n",
    "    shutil.move(ruta_tmp, ruta_real)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "460098d5-069f-4d05-8e4d-21434c5603ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creacion del archivo .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53869ed0-e6c2-4479-9a18-3e51cc2979b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script inputs.ipynb"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "inputs",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
